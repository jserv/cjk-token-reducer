use once_cell::sync::Lazy;
use regex::Regex;

#[derive(Debug, Clone)]
pub struct PreservedSegment {
    pub placeholder: String,
    pub original: String,
    pub segment_type: SegmentType,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum SegmentType {
    CodeBlock,
    InlineCode,
    Url,
    FilePath,
    NoTranslate, // User-marked text [[...]] or ==...==
    EnglishTerm, // Auto-detected English technical terms in CJK text
}

pub struct PreserveResult {
    pub text: String,
    pub segments: Vec<PreservedSegment>,
}

// Lazy-compiled regexes (compiled once, reused)
static CODE_BLOCK_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"```[\s\S]*?```").unwrap());
static INLINE_CODE_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"`[^`]+`").unwrap());
// Exclude trailing punctuation from URLs
static URL_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://[^\s]*[^\s.,;)]").unwrap());
static FILE_PATH_RE: Lazy<Regex> =
    Lazy::new(|| Regex::new(r"(?:\.\.?/)?(?:[\w.\-]+/)+[\w.\-]+(?:\.\w+)?").unwrap());

// No-translate markers: [[text]] and ==text==
static WIKI_MARKER_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"\[\[([^\]]+)\]\]").unwrap());
static HIGHLIGHT_MARKER_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"==([^=]+)==").unwrap());

// English technical terms: camelCase, PascalCase, SCREAMING_CASE, snake_case identifiers
// Matches: getUserData, API_KEY, MyClass, fetch_results, MAX_SIZE, getURLData, XMLParser
static ENGLISH_TERM_RE: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"(?x)
        # camelCase with acronyms: getURLData, parseXMLFile, myHTTPClient
        [a-z]+(?:[A-Z]+[a-z]*)+  |
        # PascalCase with acronyms: XMLParser, HTTPRequest, MyURLHandler
        [A-Z]+[a-z]+(?:[A-Z]+[a-z]*)*  |
        # Acronym + PascalCase: URLParser, HTTPClient, XMLHttpRequest
        [A-Z]{2,}[a-z]+(?:[A-Z]+[a-z]*)*  |
        # SCREAMING_SNAKE_CASE (2+ parts)
        [A-Z][A-Z0-9]*(?:_[A-Z0-9]+)+ |
        # snake_case identifiers (2+ parts)
        [a-z][a-z0-9]*(?:_[a-z0-9]+)+ |
        # Common acronyms and short tech terms (standalone, 3+ chars)
        \b(?:API|URL|HTTP|JSON|XML|SQL|CSS|HTML|DOM|SDK|CLI|GUI|IDE|ORM|MVC|MVP|REST|CRUD|AJAX|UUID|UTF|ASCII|JPEG|PNG|GIF|PDF|ZIP|SSH|SSL|TLS|TCP|UDP|DNS|FTP|SMTP|IMAP|POP3|LDAP|OAuth|JWT|CORS|CSRF|XSS|CDN|AWS|GCP|VPN|IoT|CPU|GPU|RAM|SSD|HDD|USB|BIOS|UEFI|EFI|NAS|RAID)\b
    ").unwrap()
});

// === Term Detector Abstraction ===

/// A detected term with byte offsets
#[derive(Debug, Clone)]
pub struct TermMatch {
    pub text: String,
    pub start: usize,
    pub end: usize,
}

/// Trait for term detection strategies
pub trait TermDetector: Send + Sync {
    fn detect(&self, text: &str) -> Vec<TermMatch>;
}

/// Regex-based detector (all platforms, fallback behavior)
pub struct RegexTermDetector;

impl TermDetector for RegexTermDetector {
    fn detect(&self, text: &str) -> Vec<TermMatch> {
        ENGLISH_TERM_RE
            .find_iter(text)
            .filter(|m| !m.as_str().contains('\u{FEFF}')) // Skip placeholder text
            .map(|m| TermMatch {
                text: m.as_str().to_string(),
                start: m.start(),
                end: m.end(),
            })
            .collect()
    }
}

// === macOS NLP Implementation ===

#[cfg(all(target_os = "macos", feature = "macos-nlp"))]
mod macos_nlp {
    use super::*;

    // =========================================================================
    // FFI Module - All unsafe Objective-C interactions are isolated here
    // =========================================================================
    mod ffi {
        use objc2::rc::Retained;
        use objc2::ClassType;
        use objc2_foundation::{NSArray, NSCopying, NSRange, NSString, NSValue};
        use objc2_natural_language::{
            NLTagOrganizationName, NLTagPersonalName, NLTagPlaceName, NLTagSchemeNameType,
            NLTagger, NLTaggerOptions, NLTokenUnit,
        };
        use std::cell::RefCell;

        /// A named entity detected by NLTagger with UTF-16 offsets.
        /// This is the safe output from FFI - no Objective-C types exposed.
        #[derive(Debug, Clone)]
        pub struct NamedEntity {
            pub text: String,
            /// UTF-16 offset (NSString indexing)
            pub utf16_start: usize,
            /// UTF-16 length
            pub utf16_length: usize,
        }

        /// Internal cached tagger state (not exposed outside ffi module).
        struct CachedTagger {
            tagger: Retained<NLTagger>,
            name_type_scheme: Retained<NSString>,
        }

        impl CachedTagger {
            /// Create a new cached tagger. Returns None if tag scheme unavailable.
            fn new() -> Option<Self> {
                // SAFETY: NLTagSchemeNameType is a valid static constant when the
                // NaturalLanguage framework is linked (guaranteed on macOS 10.14+).
                let name_type_scheme = unsafe { NLTagSchemeNameType }?;

                let tag_schemes: Retained<NSArray<NSString>> =
                    NSArray::from_id_slice(&[name_type_scheme.copy()]);

                // SAFETY: NLTagger::alloc returns a valid allocation, and
                // initWithTagSchemes properly initializes it. The tag_schemes
                // array remains valid for the duration of this call.
                let tagger =
                    unsafe { NLTagger::initWithTagSchemes(NLTagger::alloc(), &tag_schemes) };

                Some(CachedTagger {
                    tagger,
                    name_type_scheme: name_type_scheme.copy(),
                })
            }
        }

        // Thread-local cached tagger to avoid allocation overhead per call.
        thread_local! {
            static CACHED_TAGGER: RefCell<Option<CachedTagger>> = const { RefCell::new(None) };
        }

        /// Safe wrapper for NLTagger operations.
        /// All unsafe FFI code is encapsulated within this struct's methods.
        pub struct Tagger;

        impl Tagger {
            /// Detect named entities (PersonalName, PlaceName, OrganizationName) in text.
            /// Returns entities with UTF-16 offsets (caller must convert to UTF-8).
            ///
            /// This is the single safe entry point for NLTagger operations.
            /// All unsafe Objective-C interactions are contained within this method.
            pub fn detect_named_entities(text: &str) -> Vec<NamedEntity> {
                let mut entities = Vec::new();

                // Create NSString from Rust string (safe - objc2 handles encoding)
                let ns_string = NSString::from_str(text);

                CACHED_TAGGER.with(|cache| {
                    let mut cache = cache.borrow_mut();

                    // Lazily initialize the cached tagger
                    if cache.is_none() {
                        *cache = CachedTagger::new();
                    }

                    let Some(cached) = cache.as_ref() else {
                        // Tag scheme unavailable - return empty
                        return;
                    };

                    // SAFETY: tagger and ns_string are valid Retained objects.
                    // ns_string remains valid for the duration of this closure.
                    unsafe { cached.tagger.setString(Some(&ns_string)) };

                    let range = NSRange::new(0, ns_string.length());
                    // NLTaggerOmitOther prevents NSNull in tags array for unrecognized tokens
                    let options = NLTaggerOptions::NLTaggerOmitPunctuation
                        | NLTaggerOptions::NLTaggerOmitWhitespace
                        | NLTaggerOptions::NLTaggerOmitOther
                        | NLTaggerOptions::NLTaggerJoinNames;

                    let mut token_ranges_out: Option<Retained<NSArray<NSValue>>> = None;

                    // SAFETY: All parameters are valid:
                    // - range is within ns_string bounds (0..length)
                    // - name_type_scheme is a valid tag scheme
                    // - token_ranges_out is a valid out-parameter
                    let tags = unsafe {
                        cached.tagger.tagsInRange_unit_scheme_options_tokenRanges(
                            range,
                            NLTokenUnit::Word,
                            &cached.name_type_scheme,
                            options,
                            Some(&mut token_ranges_out),
                        )
                    };

                    // SAFETY: These are valid static constants from the framework.
                    let personal_name = unsafe { NLTagPersonalName };
                    let place_name = unsafe { NLTagPlaceName };
                    let org_name = unsafe { NLTagOrganizationName };

                    if let Some(token_ranges) = token_ranges_out {
                        let count = tags.count().min(token_ranges.count());

                        for idx in 0..count {
                            // SAFETY: idx is within bounds due to min() above.
                            let tag = unsafe { tags.objectAtIndex(idx) };
                            let range_value = unsafe { token_ranges.objectAtIndex(idx) };

                            // Check if this is a named entity type we care about
                            // SAFETY: isEqualToString is safe to call on valid NSString refs.
                            let is_named_entity = personal_name
                                .is_some_and(|pn| unsafe { tag.isEqualToString(pn) })
                                || place_name.is_some_and(|pl| unsafe { tag.isEqualToString(pl) })
                                || org_name.is_some_and(|on| unsafe { tag.isEqualToString(on) });

                            if is_named_entity {
                                // SAFETY: range_value is a valid NSValue containing NSRange.
                                let token_range: NSRange = unsafe { range_value.rangeValue() };

                                // SAFETY: token_range is within ns_string bounds (from tagger).
                                let token_ns_string =
                                    unsafe { ns_string.substringWithRange(token_range) };
                                let token_text = token_ns_string.to_string();

                                entities.push(NamedEntity {
                                    text: token_text,
                                    utf16_start: token_range.location,
                                    utf16_length: token_range.length,
                                });
                            }
                        }
                    }

                    // SAFETY: Setting string to None releases the reference safely.
                    unsafe { cached.tagger.setString(None) };
                });

                entities
            }
        }

        #[cfg(test)]
        mod tests {
            use super::*;

            #[test]
            fn test_tagger_returns_entities() {
                // Basic smoke test - NLTagger should not panic
                let entities = Tagger::detect_named_entities("Tim Cook works at Apple");
                // We don't assert specific results as NER behavior may vary by OS version
                let _ = entities;
            }

            #[test]
            fn test_tagger_handles_empty_string() {
                let entities = Tagger::detect_named_entities("");
                assert!(entities.is_empty());
            }

            #[test]
            fn test_tagger_handles_no_entities() {
                let entities = Tagger::detect_named_entities("hello world");
                // May or may not find entities - just verify no panic
                let _ = entities;
            }
        }
    }

    // =========================================================================
    // Public API - Safe wrappers using the ffi module
    // =========================================================================

    pub struct MacOsTermDetector;

    impl MacOsTermDetector {
        /// Convert UTF-16 offset to UTF-8 byte offset.
        /// Pure Rust implementation - no unsafe code.
        fn utf16_to_utf8_offset(text: &str, utf16_offset: usize) -> Option<usize> {
            let mut utf16_pos = 0;
            for (byte_idx, ch) in text.char_indices() {
                if utf16_pos == utf16_offset {
                    return Some(byte_idx);
                }
                let len_utf16 = ch.len_utf16();
                // If the offset is in the middle of this character (e.g. inside a surrogate pair),
                // return the end of this character (start of next).
                if utf16_offset > utf16_pos && utf16_offset < utf16_pos + len_utf16 {
                    return Some(byte_idx + ch.len_utf8());
                }
                utf16_pos += len_utf16;
            }
            if utf16_pos == utf16_offset {
                Some(text.len())
            } else {
                None
            }
        }

        /// Check if a character is in the Latin script (including extended Latin).
        /// Covers: Basic Latin, Latin-1 Supplement (letters only), Latin Extended-A/B,
        /// Latin Extended Additional. Excludes math symbols like Ã— Ã·.
        /// Pure Rust implementation - no unsafe code.
        fn is_latin_char(c: char) -> bool {
            matches!(
                c,
                // Basic Latin (ASCII letters and digits)
                'A'..='Z' | 'a'..='z' | '0'..='9' |
                // Common punctuation allowed in names
                ' ' | '-' | '\'' | '.' | ',' |
                // Latin-1 Supplement letters (excluding Ã— at U+00D7 and Ã· at U+00F7)
                '\u{00C0}'..='\u{00D6}' |  // Ã€-Ã–
                '\u{00D8}'..='\u{00F6}' |  // Ã˜-Ã¶
                '\u{00F8}'..='\u{00FF}' |  // Ã¸-Ã¿
                // Latin Extended-A (Ä€-Å¿)
                '\u{0100}'..='\u{017F}' |
                // Latin Extended-B (Æ€-É)
                '\u{0180}'..='\u{024F}' |
                // Latin Extended Additional (á¸€-á»¿, Vietnamese, etc.)
                '\u{1E00}'..='\u{1EFF}'
            )
        }

        /// Check if string contains only Latin script characters.
        /// Allows names like "RenÃ©", "MÃ¼nchen", "FranÃ§ois" while excluding CJK.
        /// Pure Rust implementation - no unsafe code.
        fn is_latin_only(s: &str) -> bool {
            s.chars().all(Self::is_latin_char)
        }
    }

    impl TermDetector for MacOsTermDetector {
        fn detect(&self, text: &str) -> Vec<TermMatch> {
            // Start with regex-based detection for technical terms
            let mut results = RegexTermDetector.detect(text);

            // Helper to check if a new range overlaps with any existing matches
            let is_overlapping = |start: usize, end: usize, existing: &[TermMatch]| -> bool {
                existing.iter().any(|m| {
                    // Check for intersection: max(start1, start2) < min(end1, end2)
                    start.max(m.start) < end.min(m.end)
                })
            };

            // Use the safe FFI wrapper to detect named entities
            let entities = ffi::Tagger::detect_named_entities(text);

            // Process entities - add NLP-detected named entities that regex missed
            for entity in entities {
                // Skip entities that overlap with existing placeholders (contain FEFF marker)
                // This prevents corruption when NLP runs on text with prior placeholder insertions
                if entity.text.contains('\u{FEFF}') {
                    continue;
                }

                // Only preserve Latin script names (excludes CJK like "å¼ ä¼Ÿ")
                // but includes names like "RenÃ©", "MÃ¼nchen", "FranÃ§ois"
                if Self::is_latin_only(&entity.text) && !entity.text.is_empty() {
                    // Convert UTF-16 offsets to UTF-8 byte offsets
                    if let (Some(start), Some(end)) = (
                        Self::utf16_to_utf8_offset(text, entity.utf16_start),
                        Self::utf16_to_utf8_offset(text, entity.utf16_start + entity.utf16_length),
                    ) {
                        // Only add if not already covered by regex (prevent partial overlaps)
                        if !is_overlapping(start, end, &results) {
                            results.push(TermMatch {
                                text: entity.text,
                                start,
                                end,
                            });
                        }
                    }
                }
            }

            results
        }
    }

    #[cfg(test)]
    mod tests {
        use super::*;

        #[test]
        fn test_utf16_to_utf8_offset_ascii() {
            let text = "hello world";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0));
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 5), Some(5));
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 11), Some(11));
        }

        #[test]
        fn test_utf16_to_utf8_offset_cjk() {
            // Korean: "ì•ˆë…•" (2 chars, 6 UTF-8 bytes, 1 UTF-16 code unit each)
            let text = "ì•ˆë…•";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0));
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 1), Some(3)); // After first char
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(6));
            // End
        }

        #[test]
        fn test_utf16_to_utf8_offset_mixed() {
            // "Hiì•ˆë…•" - 2 ASCII + 2 Korean
            let text = "Hiì•ˆë…•";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0)); // H
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(2)); // After "Hi"
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 3), Some(5)); // After "Hiì•ˆ"
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 4), Some(8));
            // End
        }

        #[test]
        fn test_is_latin_only() {
            // Basic ASCII
            assert!(MacOsTermDetector::is_latin_only("hello"));
            assert!(MacOsTermDetector::is_latin_only("Tim Cook"));
            assert!(MacOsTermDetector::is_latin_only("Apple123"));
            // Latin extended characters (accents, umlauts)
            assert!(MacOsTermDetector::is_latin_only("RenÃ©"));
            assert!(MacOsTermDetector::is_latin_only("MÃ¼nchen"));
            assert!(MacOsTermDetector::is_latin_only("JosÃ© GarcÃ­a"));
            assert!(MacOsTermDetector::is_latin_only("ZÃ¼rich"));
            assert!(MacOsTermDetector::is_latin_only("Ã…ngstrÃ¶m"));
            // CJK should be rejected
            assert!(!MacOsTermDetector::is_latin_only("å¼ ä¼Ÿ"));
            assert!(!MacOsTermDetector::is_latin_only("Timå¼ "));
            assert!(!MacOsTermDetector::is_latin_only("æ±äº¬"));
            assert!(!MacOsTermDetector::is_latin_only("ì„œìš¸"));
            // Math symbols should be rejected (Ã— = U+00D7, Ã· = U+00F7)
            assert!(!MacOsTermDetector::is_latin_only("3Ã—4"));
            assert!(!MacOsTermDetector::is_latin_only("8Ã·2"));
        }

        #[test]
        fn test_macos_detector_basic() {
            let detector = MacOsTermDetector;
            // This tests that the detector can be instantiated and called
            // Actual NER results depend on the macOS NLP model
            let _matches = detector.detect("Tim Cook works at Apple");
            // We don't assert specific results as NER behavior may vary
        }

        #[test]
        fn test_macos_detector_filters_cjk_names() {
            let detector = MacOsTermDetector;
            let matches = detector.detect("å¼ ä¼Ÿ works at è‹¹æœå…¬å¸");
            // Should NOT preserve Chinese names (filtered by is_latin_only)
            assert!(!matches.iter().any(|m| m.text.contains('å¼ ')));
            assert!(!matches.iter().any(|m| m.text.contains('è‹¹')));
        }

        // === UTF-16/UTF-8 Conversion Edge Cases (Emoji & Surrogate Pairs) ===

        #[test]
        fn test_utf16_to_utf8_offset_basic_emoji() {
            // ğŸ˜€ = U+1F600, requires UTF-16 surrogate pair (D83D DE00)
            let text = "HiğŸ˜€World";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0)); // H
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 1), Some(1)); // i
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(2)); // ğŸ˜€ start
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 3), Some(6)); // After ğŸ˜€ (2 UTF-16 units, 4 UTF-8 bytes)
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 4), Some(6)); // W
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 9), Some(11));
            // End
        }

        #[test]
        fn test_utf16_to_utf8_offset_multi_emoji() {
            // "ğŸ‰ğŸš€" = two emoji with surrogate pairs
            let text = "ğŸ‰ğŸš€";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0));
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(4)); // After ğŸ‰
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 4), Some(8));
            // End
        }

        #[test]
        fn test_utf16_to_utf8_offset_zwj_sequence() {
            // ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ = family emoji with ZWJ (multiple code points, multiple surrogate pairs)
            let text = "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0));
            // This is a complex multi-codepoint sequence (4 emojis + 3 ZWJ)
            // Each emoji is 2 UTF-16 units, each ZWJ is 1 UTF-16 unit
            // Total: 4*2 + 3 = 11 UTF-16 units
            // UTF-8: 4*4 + 3*3 = 25 bytes
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 11), Some(25));
        }

        #[test]
        fn test_utf16_to_utf8_offset_skin_tone_modifier() {
            // ğŸ‘ğŸ½ = thumbs up with medium skin tone modifier
            let text = "ğŸ‘ğŸ½";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0));
            // ğŸ‘ = U+1F44D (2 UTF-16 units, 4 UTF-8 bytes)
            // ğŸ½ = U+1F3FD (2 UTF-16 units, 4 UTF-8 bytes)
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(4));
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 4), Some(8));
        }

        #[test]
        fn test_utf16_to_utf8_offset_regional_flag() {
            // ğŸ‡ºğŸ‡¸ = US flag (regional indicator symbols)
            let text = "ğŸ‡ºğŸ‡¸";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0));
            // Each regional indicator is 2 UTF-16 units, 4 UTF-8 bytes.
            // Offset 1 is inside the first flag (ğŸ‡º), so it returns the end of ğŸ‡º (4).
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 1), Some(4));
            // Offset 2 is the start of the second flag (ğŸ‡¸).
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(4));
        }

        #[test]
        fn test_utf16_to_utf8_offset_variation_selector() {
            // â¤ï¸ = heart with variation selector-16
            let text = "â¤ï¸";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0));
            // â¤ = U+2764 (1 UTF-16 unit, 3 UTF-8 bytes)
            // ï¸ = U+FE0F (1 UTF-16 unit, 3 UTF-8 bytes)
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 1), Some(3));
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(6));
        }

        #[test]
        fn test_utf16_to_utf8_offset_cjk_ideograph() {
            // é¾ = U+9F8C (a complex CJK character)
            let text = "é¾";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0));
            // This is a BMP character, so 1 UTF-16 unit, 3 UTF-8 bytes
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 1), Some(3));
        }

        #[test]
        fn test_utf16_to_utf8_offset_cjk_extension() {
            // ğ ®· = U+20BB7 (CJK Unified Ideograph Extension B, outside BMP)
            let text = "ğ ®·";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0));
            // This is outside BMP, so 2 UTF-16 units, 4 UTF-8 bytes
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(4));
        }

        #[test]
        fn test_utf16_to_utf8_offset_complex_mixed() {
            // "HiğŸ˜€ì•ˆë…•ğŸ‰" = ASCII + emoji + CJK + emoji
            let text = "HiğŸ˜€ì•ˆë…•ğŸ‰";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 0), Some(0)); // H
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(2)); // After "Hi"
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 3), Some(6)); // After "HiğŸ˜€" (emoji=4 bytes)
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 5), Some(9)); // After "HiğŸ˜€ì•ˆ" (Korean=3 bytes)
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 6), Some(12)); // After "HiğŸ˜€ì•ˆë…•"
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 8), Some(16));
            // End (ğŸ‰=4 bytes)
        }

        #[test]
        fn test_utf16_to_utf8_offset_invalid_returns_none() {
            // Test offset beyond string length
            let text = "Hello";
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 100), None);
        }

        #[test]
        fn test_utf16_to_utf8_offset_in_middle_of_surrogate_pair() {
            // Test offset in the middle of a surrogate pair
            let text = "HiğŸ˜€World";
            // UTF-16: H i D83D DE00 W o r l d
            // UTF-8 offsets for UTF-16 positions: 0, 1, 2, 6, 7, 8, 9, 10, 11, 12
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 2), Some(2));
            assert_eq!(MacOsTermDetector::utf16_to_utf8_offset(text, 3), Some(6));
        }

        #[test]
        fn test_mixed_latin_cjk_emoji_preservation() {
            let text = "The API call uses ì•ˆë…•í•˜ì„¸ìš” with ğŸ‰ celebration";
            let config = PreserveConfig::all();
            let result = extract_and_preserve_with_config(text, &config);

            // Should preserve "API" as EnglishTerm
            let eng_terms: Vec<_> = result
                .segments
                .iter()
                .filter(|s| s.segment_type == SegmentType::EnglishTerm)
                .collect();
            assert!(eng_terms.iter().any(|s| s.original == "API"));
        }
    }
}

/// Get the appropriate term detector for the platform and configuration
#[allow(unused_variables)]
pub fn get_term_detector(use_nlp: bool) -> Box<dyn TermDetector> {
    #[cfg(all(target_os = "macos", feature = "macos-nlp"))]
    if use_nlp {
        return Box::new(macos_nlp::MacOsTermDetector);
    }

    Box::new(RegexTermDetector)
}

/// Configuration for preservation behavior
#[derive(Debug, Clone, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct PreserveConfig {
    /// Enable [[...]] wiki-style markers
    #[serde(default = "default_true")]
    pub wiki_markers: bool,
    /// Enable ==...== highlight-style markers
    #[serde(default = "default_true")]
    pub highlight_markers: bool,
    /// Enable auto-detection of English technical terms in CJK text
    #[serde(default = "default_true")]
    pub english_terms: bool,
    /// Use macOS NLP for term detection (macOS only, falls back to regex)
    #[serde(default = "default_true")]
    pub use_nlp: bool,
}

fn default_true() -> bool {
    true
}

impl Default for PreserveConfig {
    fn default() -> Self {
        Self {
            wiki_markers: true,
            highlight_markers: true,
            english_terms: true,
            use_nlp: true,
        }
    }
}

impl PreserveConfig {
    /// Default config: all preservation features enabled
    pub fn all() -> Self {
        Self {
            wiki_markers: true,
            highlight_markers: true,
            english_terms: true,
            use_nlp: true, // Enable NLP by default on macOS
        }
    }

    /// Config with only basic preservation (code, URLs, paths)
    pub fn basic() -> Self {
        Self {
            wiki_markers: false,
            highlight_markers: false,
            english_terms: false,
            use_nlp: false,
        }
    }
}

/// Get the type string for a segment type (used in placeholder generation)
fn segment_type_str(segment_type: SegmentType) -> &'static str {
    match segment_type {
        SegmentType::CodeBlock => "code",
        SegmentType::InlineCode => "inline",
        SegmentType::Url => "url",
        SegmentType::FilePath => "path",
        SegmentType::NoTranslate => "notrans",
        SegmentType::EnglishTerm => "engterm",
    }
}

/// Replace regex matches with placeholders, collecting preserved segments.
/// If `use_capture_group` is true, stores only capture group 1 (for markers like [[text]]).
/// Otherwise stores the full match.
fn replace_with_placeholders(
    text: &str,
    regex: &Regex,
    segment_type: SegmentType,
    segments: &mut Vec<PreservedSegment>,
    index: &mut usize,
    use_capture_group: bool,
) -> String {
    let type_str = segment_type_str(segment_type);
    regex
        .replace_all(text, |caps: &regex::Captures| {
            let original = if use_capture_group {
                caps.get(1)
                    .map(|m| m.as_str())
                    .unwrap_or(&caps[0])
                    .to_string()
            } else {
                caps[0].to_string()
            };
            let placeholder = format!("\u{FEFF}cjk{type_str}{index}\u{FEFF}");
            segments.push(PreservedSegment {
                placeholder: placeholder.clone(),
                original,
                segment_type,
            });
            *index += 1;
            placeholder
        })
        .into_owned()
}

/// Extract code blocks, inline code, URLs, and file paths, replacing with placeholders
/// Uses default config (basic preservation only)
pub fn extract_and_preserve(text: &str) -> PreserveResult {
    extract_and_preserve_with_config(text, &PreserveConfig::default())
}

/// Extract and preserve with configurable options
pub fn extract_and_preserve_with_config(text: &str, config: &PreserveConfig) -> PreserveResult {
    let mut segments = Vec::new();
    let mut index = 0;

    // Priority order: code blocks > inline code > no-translate markers > URLs > file paths > English terms
    // Higher priority patterns are extracted first to prevent overlap

    // 1. Code blocks (highest priority - multiline)
    let mut result = replace_with_placeholders(
        text,
        &CODE_BLOCK_RE,
        SegmentType::CodeBlock,
        &mut segments,
        &mut index,
        false,
    );

    // 2. Inline code
    result = replace_with_placeholders(
        &result,
        &INLINE_CODE_RE,
        SegmentType::InlineCode,
        &mut segments,
        &mut index,
        false,
    );

    // 3. No-translate markers [[...]] (wiki-style) - uses capture group for inner content
    if config.wiki_markers {
        result = replace_with_placeholders(
            &result,
            &WIKI_MARKER_RE,
            SegmentType::NoTranslate,
            &mut segments,
            &mut index,
            true,
        );
    }

    // 4. No-translate markers ==...== (highlight-style) - uses capture group for inner content
    if config.highlight_markers {
        result = replace_with_placeholders(
            &result,
            &HIGHLIGHT_MARKER_RE,
            SegmentType::NoTranslate,
            &mut segments,
            &mut index,
            true,
        );
    }

    // 5. URLs
    result = replace_with_placeholders(
        &result,
        &URL_RE,
        SegmentType::Url,
        &mut segments,
        &mut index,
        false,
    );

    // 6. File paths
    result = replace_with_placeholders(
        &result,
        &FILE_PATH_RE,
        SegmentType::FilePath,
        &mut segments,
        &mut index,
        false,
    );

    // 7. English technical terms (lowest priority - only in remaining text)
    // Uses either macOS NLP (if enabled and available) or regex fallback
    if config.english_terms {
        let detector = get_term_detector(config.use_nlp);
        let mut terms = detector.detect(&result);

        // Sort by start position descending to process in reverse order
        // This preserves byte indices during replacement
        terms.sort_by(|a, b| b.start.cmp(&a.start));

        for term in terms {
            let placeholder = format!("\u{FEFF}cjkengterm{index}\u{FEFF}");
            segments.push(PreservedSegment {
                placeholder: placeholder.clone(),
                original: term.text,
                segment_type: SegmentType::EnglishTerm,
            });
            result.replace_range(term.start..term.end, &placeholder);
            index += 1;
        }
    }

    PreserveResult {
        text: result,
        segments,
    }
}

/// Restore preserved segments back to original text
pub fn restore_preserved(text: &str, segments: &[PreservedSegment]) -> String {
    let mut result = text.to_string();
    // Restore in reverse order to avoid collisions where a restored segment
    // contains text that looks like a later placeholder.
    for segment in segments.iter().rev() {
        result = result.replace(&segment.placeholder, &segment.original);
    }
    result
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_code_block_preservation() {
        let text = "ì´ ì½”ë“œ ìˆ˜ì •í•´ì¤˜\n```rust\nfn main() {}
```";
        let result = extract_and_preserve(text);
        assert_eq!(result.segments.len(), 1);
        assert!(result.text.contains("cjkcode"));
        assert!(result.segments[0].original.contains("fn main()"));
    }

    #[test]
    fn test_inline_code_preservation() {
        let text = "í•¨ìˆ˜ `foo()` í˜¸ì¶œí•´ì¤˜";
        let result = extract_and_preserve(text);
        assert_eq!(result.segments.len(), 1);
        assert!(result.text.contains("cjkinline"));
        assert_eq!(result.segments[0].original, "`foo()`");
    }

    #[test]
    fn test_url_preservation() {
        let text = "https://github.com/foo ì´ ë§í¬ ì°¸ê³ í•´";
        let result = extract_and_preserve(text);
        assert!(result
            .segments
            .iter()
            .any(|s| s.original.contains("github.com")));
    }

    #[test]
    fn test_url_punctuation_exclusion() {
        let text = "Check https://github.com/foo.";
        let result = extract_and_preserve(text);
        let segment = result
            .segments
            .iter()
            .find(|s| matches!(s.segment_type, SegmentType::Url))
            .unwrap();
        assert_eq!(segment.original, "https://github.com/foo"); // Dot should not be included
        assert!(result.text.ends_with(".")); // Dot should remain in text
    }

    #[test]
    fn test_file_path_preservation() {
        let text = "./src/main.rs íŒŒì¼ ìˆ˜ì •í•´ì¤˜";
        let result = extract_and_preserve(text);
        assert!(result
            .segments
            .iter()
            .any(|s| s.original.contains("src/main.rs")));
    }

    #[test]
    fn test_restore_order() {
        let text = "ì½”ë“œ `foo()` ìˆ˜ì • ```\nbar()
```";
        let preserved = extract_and_preserve(text);
        let restored = restore_preserved(&preserved.text, &preserved.segments);
        assert!(restored.contains("`foo()`"));
        assert!(restored.contains(
            "```\nbar()
```"
        ));
    }

    #[test]
    fn test_restore_collision() {
        // This tests that if a code block contains text that mimics a generated placeholder,
        // it doesn't get double-replaced.
        // We artificially construct a case where the user text predicts the next placeholder.
        // "Code: `__PRESERVE_URL_1__` Link: https://example.com"
        // 1. Inline matches `__PRESERVE_URL_1__` -> becomes __PRESERVE_INLINE_0__
        // 2. URL matches https://example.com -> becomes __PRESERVE_URL_1__
        // If we restore forward:
        // __PRESERVE_INLINE_0__ -> `__PRESERVE_URL_1__`
        // Then `__PRESERVE_URL_1__` -> https://example.com (WRONG)
        let text = "Code: `__PRESERVE_URL_1__` Link: https://example.com";
        let preserved = extract_and_preserve(text);
        let restored = restore_preserved(&preserved.text, &preserved.segments);
        assert_eq!(restored, text);
    }

    // === No-Translate Marker Tests ===

    #[test]
    fn test_wiki_marker_preservation() {
        let text = "ì´ í•¨ìˆ˜ëŠ” [[getUserData]]ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        // Should have one NoTranslate segment
        let no_trans: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::NoTranslate)
            .collect();
        assert_eq!(
            no_trans.len(),
            1,
            "Expected 1 NoTranslate segment, got {}",
            no_trans.len()
        );
        // Original should be inner content without markers
        assert_eq!(no_trans[0].original, "getUserData");
        // Text should have placeholder, not markers
        assert!(
            result.text.contains("cjknotrans"),
            "Expected notrans placeholder in: {}",
            result.text
        );
        assert!(!result.text.contains("[["));
    }

    #[test]
    fn test_highlight_marker_preservation() {
        let text = "==API_KEY== í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let no_trans: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::NoTranslate)
            .collect();
        assert_eq!(no_trans.len(), 1);
        assert_eq!(no_trans[0].original, "API_KEY");
        assert!(!result.text.contains("=="));
    }

    #[test]
    fn test_multiple_markers() {
        let text = "[[foo]] and ==bar== and [[baz]]";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let no_trans: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::NoTranslate)
            .collect();
        assert_eq!(no_trans.len(), 3);
        assert!(no_trans.iter().any(|s| s.original == "foo"));
        assert!(no_trans.iter().any(|s| s.original == "bar"));
        assert!(no_trans.iter().any(|s| s.original == "baz"));
    }

    #[test]
    fn test_marker_restore() {
        let text = "ì´ í•¨ìˆ˜ëŠ” [[getUserData]]ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);
        let restored = restore_preserved(&result.text, &result.segments);
        // Restored should have inner content (markers stripped)
        assert!(restored.contains("getUserData"));
        // But not the markers themselves
        assert!(!restored.contains("[["));
        assert!(!restored.contains("]]"));
    }

    #[test]
    fn test_markers_disabled() {
        let text = "[[keep]] and ==this==";
        let config = PreserveConfig::basic(); // All disabled
        let result = extract_and_preserve_with_config(text, &config);

        // No NoTranslate segments
        let no_trans: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::NoTranslate)
            .collect();
        assert_eq!(no_trans.len(), 0);
        // Markers should remain in text
        assert!(result.text.contains("[[keep]]"));
        assert!(result.text.contains("==this=="));
    }

    // === English Technical Term Tests ===

    #[test]
    fn test_camel_case_detection() {
        let text = "getUserData í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì£¼ì„¸ìš”";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert!(eng_terms.iter().any(|s| s.original == "getUserData"));
    }

    #[test]
    fn test_pascal_case_detection() {
        let text = "MyClass í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert!(eng_terms.iter().any(|s| s.original == "MyClass"));
    }

    #[test]
    fn test_screaming_snake_case_detection() {
        let text = "MAX_SIZE ìƒìˆ˜ë¥¼ ë³€ê²½í•˜ì„¸ìš”";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert!(eng_terms.iter().any(|s| s.original == "MAX_SIZE"));
    }

    #[test]
    fn test_snake_case_detection() {
        let text = "get_user_data í•¨ìˆ˜ì…ë‹ˆë‹¤";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert!(eng_terms.iter().any(|s| s.original == "get_user_data"));
    }

    #[test]
    fn test_common_acronyms() {
        let text = "API ìš”ì²­ì„ ë³´ë‚´ì„¸ìš”";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert!(eng_terms.iter().any(|s| s.original == "API"));
    }

    #[test]
    fn test_english_terms_disabled() {
        let text = "getUserData í•¨ìˆ˜";
        let mut config = PreserveConfig::all();
        config.english_terms = false;
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert_eq!(eng_terms.len(), 0);
    }

    #[test]
    fn test_mixed_preservation() {
        let text = "[[keep]] `code` getUserData API íŒŒì¼ ./src/main.rs";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        // Check all types are preserved
        assert!(result
            .segments
            .iter()
            .any(|s| s.segment_type == SegmentType::NoTranslate));
        assert!(result
            .segments
            .iter()
            .any(|s| s.segment_type == SegmentType::InlineCode));
        assert!(result
            .segments
            .iter()
            .any(|s| s.segment_type == SegmentType::EnglishTerm));
        assert!(result
            .segments
            .iter()
            .any(|s| s.segment_type == SegmentType::FilePath));
    }

    // === Acronym-in-identifier Tests (Codex review findings) ===

    #[test]
    fn test_acronym_in_camelcase() {
        let text = "getURLData parseXMLFile myHTTPClient í•¨ìˆ˜";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert!(eng_terms.iter().any(|s| s.original == "getURLData"));
        assert!(eng_terms.iter().any(|s| s.original == "parseXMLFile"));
        assert!(eng_terms.iter().any(|s| s.original == "myHTTPClient"));
    }

    #[test]
    fn test_acronym_leading_pascalcase() {
        let text = "XMLParser HTTPRequest URLHandler í´ë˜ìŠ¤";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert!(eng_terms.iter().any(|s| s.original == "XMLParser"));
        assert!(eng_terms.iter().any(|s| s.original == "HTTPRequest"));
        assert!(eng_terms.iter().any(|s| s.original == "URLHandler"));
    }

    #[test]
    fn test_xmlhttprequest_style() {
        let text = "XMLHttpRequest ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert!(eng_terms.iter().any(|s| s.original == "XMLHttpRequest"));
    }

    // === Edge case tests ===

    #[test]
    fn test_single_word_not_preserved() {
        // Single lowercase words should NOT be preserved (avoid preserving common English)
        let text = "hello world ì•ˆë…•";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        // "hello" and "world" should not be preserved
        assert!(!eng_terms.iter().any(|s| s.original == "hello"));
        assert!(!eng_terms.iter().any(|s| s.original == "world"));
    }

    #[test]
    fn test_placeholder_no_collision() {
        // Ensure placeholders don't get re-matched as English terms
        let text = "[[keep]] í…ŒìŠ¤íŠ¸";
        let config = PreserveConfig::all();
        let result = extract_and_preserve_with_config(text, &config);

        // Should only have 1 NoTranslate segment, no EnglishTerm matching placeholder
        let no_trans: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::NoTranslate)
            .collect();
        let eng_terms: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::EnglishTerm)
            .collect();
        assert_eq!(no_trans.len(), 1);
        assert_eq!(eng_terms.len(), 0);
    }

    #[test]
    fn test_extract_preserve_restore_roundtrip_simple() {
        let text = "ì´ í•¨ìˆ˜ `foo()`ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”";
        let preserved = extract_and_preserve(text);
        let restored = restore_preserved(&preserved.text, &preserved.segments);

        assert_eq!(restored, text);
    }

    #[test]
    fn test_extract_preserve_restore_roundtrip_complex() {
        let text = "ì´ ì½”ë“œ ìˆ˜ì •í•´ì¤˜\n```rust\nfn main() {}\n```\nAPI_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”";
        let preserved = extract_and_preserve(text);
        let restored = restore_preserved(&preserved.text, &preserved.segments);

        assert_eq!(restored, text);
    }

    #[test]
    fn test_extract_preserve_restore_roundtrip_all_types() {
        // Wiki markers [[...]] are intentionally stripped during extraction (capture group)
        // The expected output keeps the inner content but removes the markers
        let text = "[[keep]] `code` getUserData API ./src/main.rs https://example.com";
        let expected = "keep `code` getUserData API ./src/main.rs https://example.com";
        let config = PreserveConfig::all();
        let preserved = extract_and_preserve_with_config(text, &config);
        let restored = restore_preserved(&preserved.text, &preserved.segments);

        assert_eq!(restored, expected);
    }

    #[test]
    fn test_extract_preserve_empty_text() {
        let text = "";
        let preserved = extract_and_preserve(text);

        assert_eq!(preserved.text, "");
        assert!(preserved.segments.is_empty());
    }

    #[test]
    fn test_extract_preserve_no_segments() {
        let text = "ì´ í…ìŠ¤íŠ¸ëŠ” ë³´í˜¸í•  ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤";
        let preserved = extract_and_preserve(text);

        // No segments should be extracted
        assert!(preserved.segments.is_empty());
        assert_eq!(preserved.text, text);
    }

    #[test]
    fn test_regex_term_detector_filters_placeholders() {
        // Ensure regex detector doesn't match placeholder text itself
        let text = "\u{FEFF}cjkengterm0\u{FEFF} should not be matched";
        let detector = RegexTermDetector;
        let matches = detector.detect(text);

        // Should not match the placeholder
        assert!(!matches.iter().any(|m| m.text.contains("cjkengterm")));
    }

    #[test]
    fn test_term_match_properties() {
        let text = "getUserData í•¨ìˆ˜";
        let detector = RegexTermDetector;
        let matches = detector.detect(text);

        assert!(!matches.is_empty());
        let term = &matches[0];
        assert_eq!(term.text, "getUserData");
        assert_eq!(term.start, 0);
        // End position should be after "getUserData"
        assert!(term.end > 0);
    }

    // === Term Detection Overlap Tests ===

    #[test]
    fn test_adjacent_terms_no_overlap() {
        let text = "getUserDataAPI í•¨ìˆ˜";
        let detector = RegexTermDetector;
        let matches = detector.detect(text);

        // The regex may match "getUserDataAPI" as a single camelCase identifier
        // or may split it differently - verify we get at least one valid match
        assert!(!matches.is_empty(), "Should detect at least one term");
        // Verify that match covers the identifier portion
        let has_valid_match = matches
            .iter()
            .any(|m| m.text.starts_with("get") || m.text.contains("API"));
        assert!(has_valid_match, "Should detect identifier terms");
    }

    #[test]
    fn test_nested_term_patterns() {
        let text = "parseXMLFileData í•¨ìˆ˜";
        let detector = RegexTermDetector;
        let matches = detector.detect(text);

        // Should detect the full identifier "parseXMLFileData"
        // Not multiple overlapping matches
        assert!(matches.iter().any(|m| m.text == "parseXMLFileData"));
    }

    #[test]
    fn test_screaming_case_prefix_in_camel() {
        let text = "XMLParserClass í´ë˜ìŠ¤";
        let detector = RegexTermDetector;
        let matches = detector.detect(text);

        // Should detect "XMLParserClass" as PascalCase
        assert!(matches.iter().any(|m| m.text == "XMLParserClass"));
    }

    #[test]
    fn test_multiple_terms_in_sequence() {
        let text = "getUserDataFromAPIWithXMLParser í•¨ìˆ˜";
        let detector = RegexTermDetector;
        let matches = detector.detect(text);

        // Should detect the full camelCase identifier
        assert!(matches
            .iter()
            .any(|m| m.text == "getUserDataFromAPIWithXMLParser"));
    }

    #[test]
    fn test_acronym_boundary_detection() {
        let text = "URLParserHTTPClient í´ë˜ìŠ¤";
        let detector = RegexTermDetector;
        let matches = detector.detect(text);

        // Should detect as single PascalCase identifier
        assert!(matches.iter().any(|m| m.text == "URLParserHTTPClient"));
    }

    #[test]
    fn test_underscore_acronym_boundary() {
        let text = "API_KEY_USER_ID ë³€ìˆ˜";
        let detector = RegexTermDetector;
        let matches = detector.detect(text);

        // Should detect as single SCREAMING_SNAKE_CASE
        assert!(matches.iter().any(|m| m.text == "API_KEY_USER_ID"));
    }

    // === Emoji and Complex Character Preservation Tests ===

    #[test]
    fn test_emoji_with_code_preservation() {
        let text = "Use `console.log('ğŸ‰')` for celebration";
        let result = extract_and_preserve(text);

        // Should preserve the inline code block
        let inline_codes: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::InlineCode)
            .collect();
        assert_eq!(inline_codes.len(), 1);
        assert!(inline_codes[0].original.contains("ğŸ‰"));
    }

    #[test]
    fn test_emoji_in_url() {
        let text = "Visit https://example.com/path/ğŸ‰test for more";
        let result = extract_and_preserve(text);

        // Should preserve URL including emoji
        let urls: Vec<_> = result
            .segments
            .iter()
            .filter(|s| s.segment_type == SegmentType::Url)
            .collect();
        assert_eq!(urls.len(), 1);
        assert!(urls[0].original.contains("ğŸ‰"));
    }

    #[test]
    fn test_zwj_sequence_preservation() {
        // Test that complex emoji sequences are handled
        let text = "Family: ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ is nice";
        let result = extract_and_preserve(text);

        // Should not crash or corrupt emoji sequence
        let restored = restore_preserved(&result.text, &result.segments);
        assert!(restored.contains("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦"));
    }

    #[test]
    fn test_multiple_complex_emoji_preservation() {
        let text = "Emojis: ğŸ‰ğŸš€â¤ï¸ğŸ‘ğŸ½ğŸ‡ºğŸ‡¸ are fun";
        let result = extract_and_preserve(text);
        let restored = restore_preserved(&result.text, &result.segments);

        // All emoji should be preserved through roundtrip
        assert!(restored.contains("ğŸ‰"));
        assert!(restored.contains("ğŸš€"));
        assert!(restored.contains("â¤ï¸"));
        assert!(restored.contains("ğŸ‘ğŸ½"));
        assert!(restored.contains("ğŸ‡ºğŸ‡¸"));
    }

    #[test]
    fn test_emoji_variation_selectors_preservation() {
        let text = "Hearts: â¤ â¤ï¸ are different";
        let result = extract_and_preserve(text);
        let restored = restore_preserved(&result.text, &result.segments);

        // Both forms should be preserved
        assert!(restored.contains("â¤"));
        assert!(restored.contains("â¤ï¸"));
    }

    #[test]
    fn test_korean_japanese_chinese_mixed() {
        let text = "Korean: ì•ˆë…• Japanese: ã“ã‚“ã«ã¡ã¯ Chinese: ä½ å¥½";
        let result = extract_and_preserve(text);
        let restored = restore_preserved(&result.text, &result.segments);

        // All scripts should be preserved
        assert!(restored.contains("ì•ˆë…•"));
        assert!(restored.contains("ã“ã‚“ã«ã¡ã¯"));
        assert!(restored.contains("ä½ å¥½"));
    }

    #[test]
    fn test_beyond_bmp_cjk_with_emoji() {
        // ğ ®· = U+20BB7 (CJK Extension B)
        let text = "Use ğ ®· with ğŸ‰ emoji";
        let result = extract_and_preserve(text);
        let restored = restore_preserved(&result.text, &result.segments);

        // Beyond BMP CJK character should be preserved
        assert!(restored.contains("ğ ®·"));
        assert!(restored.contains("ğŸ‰"));
    }

    #[test]
    fn test_preserver_with_combining_diacritics() {
        // cafÃ© with combining acute accent
        let text = "Use cafÃ© for coffee";
        let result = extract_and_preserve(text);
        let restored = restore_preserved(&result.text, &result.segments);

        // Combining characters should be preserved
        assert!(restored.contains("cafÃ©"));
    }

    #[test]
    fn test_preserver_with_zero_width_joiner_in_text() {
        let text = "Check: ğŸ‘¨â€ğŸš€ is astronaut";
        let result = extract_and_preserve(text);
        let restored = restore_preserved(&result.text, &result.segments);

        // ZWJ sequences should be preserved intact
        assert!(restored.contains("ğŸ‘¨â€ğŸš€"));
    }
}
